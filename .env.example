# Example configuration for switching between LLM providers
# Copy this to .env in your project root directory

# Choose your LLM provider: "ollama" or "openai"
LLM_PROVIDER=openai

# If using OpenAI, set your API key
OPENAI_API_KEY=your_openai_api_key_here

# If using Ollama with a custom base URL
# OLLAMA_BASE_URL=http://localhost:11434
